{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addressed-force",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This script was used to generate Important Features for all 12 optimized clusters each for Sampel 1 & 2\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "  \n",
    "# Load lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = stopwords.words('english')+['climate','change','amp','deleted','climate change','don','amp nbsp','don know','people','cunt','cunt cunt']\n",
    "\n",
    "# Load the cleaned data from \"PreProcessedData.csv\" file\n",
    "df = pd.read_csv(\"PreProcessedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-collapse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1 size: 150000\n",
      "\n",
      "Cluster sizes:\n",
      " 1     27980\n",
      "9     21779\n",
      "11    20154\n",
      "12    13809\n",
      "4     13648\n",
      "6     10303\n",
      "8      8970\n",
      "3      6980\n",
      "7      6820\n",
      "2      6661\n",
      "5      6543\n",
      "10     6353\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 1\n",
      " 0    122020\n",
      "1     27980\n",
      "Name: Binary Cluster 1, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 1 - Important Features with weights\n",
      " [('energy', 0.11637725244070947), ('solar', 0.10032690704042617), ('oil', 0.09531111682657499), ('nuclear', 0.06062058676366141), ('power', 0.038917217599615805), ('renewable', 0.029919166746907342), ('electric', 0.022854083086580913), ('wind', 0.02170593486322998), ('gas', 0.017266946449892698), ('fuel', 0.016178770051855938)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 2\n",
      " 0    143339\n",
      "1      6661\n",
      "Name: Binary Cluster 2, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 2 - Important Features with weights\n",
      " [('carbon', 0.14273413448219205), ('coal', 0.12032953860703305), ('emission', 0.10763324742861592), ('pollution', 0.06648795249847991), ('air', 0.030177581268994644), ('greenhouse', 0.018786129687145478), ('gas', 0.011883711016421175), ('china', 0.00994602433109197), ('epa', 0.008683808752721544), ('energy', 0.007714245669287669)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 3\n",
      " 0    143020\n",
      "1      6980\n",
      "Name: Binary Cluster 3, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 3 - Important Features with weights\n",
      " [('trump', 0.1857735787509794), ('obama', 0.06264868189520995), ('party', 0.044960443141909064), ('president', 0.024810380500447097), ('green', 0.017477520015274715), ('epa', 0.014400432254799011), ('vote', 0.01258056788506418), ('bill', 0.01211807148802841), ('house', 0.010380060420803356), ('energy', 0.008686683386886246)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 4\n",
      " 0    136352\n",
      "1     13648\n",
      "Name: Binary Cluster 4, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 4 - Important Features with weights\n",
      " [('warming', 0.06310773166604769), ('global', 0.03685976292769358), ('science', 0.030279054861336977), ('scientist', 0.03014070543471245), ('action', 0.010808647918910673), ('new', 0.009536206037214995), ('report', 0.007753228445765318), ('world', 0.007554054919234844), ('say', 0.006930384158426542), ('crisis', 0.006784329307160113)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 5\n",
      " 0    143457\n",
      "1      6543\n",
      "Name: Binary Cluster 5, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 5 - Important Features with weights\n",
      " [('ice', 0.12201822320347208), ('temperature', 0.07403871188594936), ('arctic', 0.07203073173154592), ('warming', 0.03157786762182432), ('record', 0.02939067749413406), ('sea', 0.024758483149520297), ('global', 0.020196108194966676), ('year', 0.014944156674679387), ('level', 0.013516001384038228), ('heat', 0.012988358862252984)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 6\n",
      " 0    139697\n",
      "1     10303\n",
      "Name: Binary Cluster 6, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 6 - Important Features with weights\n",
      " [('collapse', 0.057241342803408084), ('population', 0.02904772488495197), ('world', 0.02141897184993892), ('crisis', 0.016539935560871695), ('america', 0.014493587509258742), ('growth', 0.012827140838083208), ('american', 0.010991878637113293), ('economy', 0.01092676472898837), ('economic', 0.010304225676654276), ('global', 0.009868756820119817)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 7\n",
      " 0    143180\n",
      "1      6820\n",
      "Name: Binary Cluster 7, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 7 - Important Features with weights\n",
      " [('plastic', 0.1074295293965516), ('waste', 0.06661540867732485), ('bag', 0.05045032267587361), ('bottle', 0.028960747293499477), ('use', 0.024238561593571035), ('recycling', 0.02414002964451444), ('zero', 0.02313510462293294), ('made', 0.01810111753843071), ('old', 0.016417073683512206), ('paper', 0.012569659733073894)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 8\n",
      " 0    141030\n",
      "1      8970\n",
      "Name: Binary Cluster 8, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 8 - Important Features with weights\n",
      " [('water', 0.025241178013122458), ('chemical', 0.016128875833394694), ('ban', 0.01579692678339465), ('epa', 0.011642379126869036), ('new', 0.011358470967435365), ('california', 0.010104173749148881), ('government', 0.009883571178895463), ('state', 0.007839483831364276), ('food', 0.007615233193474422), ('public', 0.007456271480509744)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 9\n",
      " 0    128221\n",
      "1     21779\n",
      "Name: Binary Cluster 9, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 9 - Important Features with weights\n",
      " [('specie', 0.03040068348573215), ('animal', 0.02632175826778387), ('ocean', 0.02557010353963506), ('wildlife', 0.022819802673606112), ('fish', 0.01979589047806266), ('bird', 0.018487303585834235), ('sea', 0.017317952490926745), ('cloud', 0.015688430375101318), ('lake', 0.010992994043571179), ('nature', 0.010908058466095166)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 10\n",
      " 0    143647\n",
      "1      6353\n",
      "Name: Binary Cluster 10, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 10 - Important Features with weights\n",
      " [('storm', 0.17184240672253664), ('hurricane', 0.15702624909269597), ('tornado', 0.10074116714863422), ('weather', 0.050930583124140075), ('cyclone', 0.028819578546381192), ('tropical', 0.02250926609638924), ('rain', 0.01291145921028385), ('forecast', 0.012537256420493676), ('hit', 0.008454132418877604), ('florida', 0.008377129252646652)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 11\n",
      " 0    129846\n",
      "1     20154\n",
      "Name: Binary Cluster 11, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 11 - Important Features with weights\n",
      " [('green', 0.037781614835985196), ('environmental', 0.03442280135397168), ('environment', 0.029451623331233166), ('sustainable', 0.02347197392817324), ('would', 0.020237753891699507), ('sustainability', 0.017157886886720073), ('like', 0.016247166262099485), ('eco', 0.013078218537425437), ('help', 0.012743081651821728), ('think', 0.012667361115516855)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 12\n",
      " 0    136191\n",
      "1     13809\n",
      "Name: Binary Cluster 12, dtype: int64\n",
      "\n",
      "Sample 1, Cluster 12 - Important Features with weights\n",
      " [('removed', 0.033966473601621396), ('energy', 0.01203008470958381), ('new', 0.009414135787586682), ('oil', 0.008339321677647208), ('year', 0.007895078699278682), ('world', 0.007613323395487146), ('solar', 0.007221701737864895), ('good', 0.00685776297726901), ('like', 0.006796400803266317), ('green', 0.006664420141112512)]\n",
      "\n",
      "Sample 2 size: 150000\n",
      "\n",
      "Cluster sizes:\n",
      " 1     27107\n",
      "11    25739\n",
      "9     23238\n",
      "4     14187\n",
      "6      9836\n",
      "12     9750\n",
      "10     8105\n",
      "3      7373\n",
      "2      6777\n",
      "7      6772\n",
      "5      6594\n",
      "8      4522\n",
      "Name: labels, dtype: int64\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 1\n",
      " 0    122893\n",
      "1     27107\n",
      "Name: Binary Cluster 1, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 1 - Important Features with weights\n",
      " [('energy', 0.11187561785767926), ('solar', 0.10241644094542801), ('oil', 0.09563654010344784), ('nuclear', 0.06207684500327307), ('power', 0.04113849618046359), ('renewable', 0.02690147565456044), ('electric', 0.025009345378736166), ('wind', 0.022208606003644858), ('gas', 0.017208448424661568), ('electricity', 0.015101169399872138)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 2\n",
      " 0    143223\n",
      "1      6777\n",
      "Name: Binary Cluster 2, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 2 - Important Features with weights\n",
      " [('carbon', 0.1329547628735615), ('coal', 0.11910516427967224), ('emission', 0.09884007056474765), ('pollution', 0.05841983538691032), ('air', 0.028372124108252766), ('greenhouse', 0.015030838085256211), ('epa', 0.014880359667330185), ('gas', 0.010289433355611078), ('china', 0.009796852741712792), ('fossil', 0.009398360953411735)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 3\n",
      " 0    142627\n",
      "1      7373\n",
      "Name: Binary Cluster 3, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 3 - Important Features with weights\n",
      " [('trump', 0.17636675703098237), ('obama', 0.0650800977280888), ('party', 0.042061662937787174), ('president', 0.024439393099657137), ('epa', 0.017329047310762697), ('green', 0.016778762479264797), ('vote', 0.012901436271417772), ('bill', 0.010653516408468556), ('new', 0.009564254773560448), ('house', 0.008933551159813022)]\n",
      "\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training binary classifier for Cluster 4\n",
      " 0    135813\n",
      "1     14187\n",
      "Name: Binary Cluster 4, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 4 - Important Features with weights\n",
      " [('warming', 0.06811621697950289), ('global', 0.04029636646972011), ('science', 0.02741685737735144), ('scientist', 0.02663788605969599), ('new', 0.00949005071856415), ('action', 0.009221311456619944), ('world', 0.008087400828072447), ('crisis', 0.007399237765577591), ('report', 0.00690277529222727), ('say', 0.006611436096686527)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 5\n",
      " 0    143406\n",
      "1      6594\n",
      "Name: Binary Cluster 5, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 5 - Important Features with weights\n",
      " [('ice', 0.13666477934078192), ('arctic', 0.07285115090234769), ('temperature', 0.06833276982348496), ('warming', 0.029703835214426846), ('record', 0.02766560388992866), ('sea', 0.024231833691792125), ('global', 0.019879525890534492), ('year', 0.013527468410024819), ('level', 0.012984423591186654), ('winter', 0.011883213051761517)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 6\n",
      " 0    140164\n",
      "1      9836\n",
      "Name: Binary Cluster 6, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 6 - Important Features with weights\n",
      " [('collapse', 0.061067951660087966), ('population', 0.0359260828171081), ('world', 0.024203803029993726), ('growth', 0.01662537903017287), ('crisis', 0.014435693000330376), ('america', 0.014384394404755717), ('economic', 0.01311359511829601), ('economy', 0.01278378602168774), ('american', 0.010054184454585747), ('global', 0.009538291853678563)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 7\n",
      " 0    143228\n",
      "1      6772\n",
      "Name: Binary Cluster 7, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 7 - Important Features with weights\n",
      " [('plastic', 0.12431333001736004), ('waste', 0.05967206176667348), ('bag', 0.05056828313348832), ('bottle', 0.029508474165439284), ('recycling', 0.025306566892179402), ('use', 0.025265600855483773), ('zero', 0.02303738646269541), ('old', 0.017986698544577642), ('paper', 0.0145709450042492), ('made', 0.011838591217247148)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 8\n",
      " 0    145478\n",
      "1      4522\n",
      "Name: Binary Cluster 8, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 8 - Important Features with weights\n",
      " [('food', 0.09252844427784064), ('farm', 0.024200121149103207), ('plant', 0.019958595833841117), ('new', 0.011004634191393024), ('chemical', 0.009768109413787158), ('study', 0.008322646958648096), ('world', 0.007832860411440951), ('year', 0.007624648754462908), ('ban', 0.007122252311264668), ('say', 0.00637107785532517)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 9\n",
      " 0    126762\n",
      "1     23238\n",
      "Name: Binary Cluster 9, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 9 - Important Features with weights\n",
      " [('specie', 0.033511226496395395), ('ocean', 0.02773679519260739), ('animal', 0.025020684806465715), ('wildlife', 0.021531492212633698), ('bird', 0.021066168214521043), ('sea', 0.01780573113549136), ('fish', 0.017013149370580058), ('nature', 0.01318520273884409), ('energy', 0.012588790163087806), ('water', 0.008505383652549582)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 10\n",
      " 0    141895\n",
      "1      8105\n",
      "Name: Binary Cluster 10, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 10 - Important Features with weights\n",
      " [('storm', 0.1498128745691826), ('hurricane', 0.12008670048033712), ('weather', 0.08486756470846066), ('tornado', 0.08060537557063506), ('cloud', 0.03484475540936232), ('rain', 0.025944396808474143), ('tropical', 0.02057291766075671), ('cyclone', 0.018390901205938708), ('forecast', 0.016091505829830093), ('hit', 0.00631034735588515)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 11\n",
      " 0    124261\n",
      "1     25739\n",
      "Name: Binary Cluster 11, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 11 - Important Features with weights\n",
      " [('environmental', 0.034237541098390514), ('green', 0.02918173303001017), ('environment', 0.02230645316947122), ('sustainable', 0.012732378476315767), ('sustainability', 0.012193293207707978), ('water', 0.011911714664961161), ('would', 0.01032751256665351), ('like', 0.009527045546897137), ('eco', 0.009472023664229827), ('help', 0.009449767197229739)]\n",
      "\n",
      "=========================================\n",
      "\n",
      "Training binary classifier for Cluster 12\n",
      " 0    140250\n",
      "1      9750\n",
      "Name: Binary Cluster 12, dtype: int64\n",
      "\n",
      "Sample 2, Cluster 12 - Important Features with weights\n",
      " [('removed', 0.024310277115359148), ('like', 0.011975705480381413), ('know', 0.011792658239934759), ('anyone', 0.01022224121589101), ('think', 0.010124208819804626), ('thought', 0.010010309185917925), ('need', 0.009957417378395948), ('guy', 0.00990681115736504), ('one', 0.008056797005633016), ('get', 0.007643668392311256)]\n",
      "Wall time: 3h 38min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create a funtion to preprocess the nltk tokenized dataframe\n",
    "def word_tokenizer(text):\n",
    "    tokenized_text = text\n",
    "    tokenized_text_proc = [token.lower() for token in tokenized_text \n",
    "                           if  (not token.lower() in stopwords) # Remove stopwords \n",
    "                           and (not len(token) <= 2)]     # Remove short tokens\n",
    "    tokenized_text_proc = [lemmatizer.lemmatize(token) for token in tokenized_text_proc]\n",
    "    return tokenized_text_proc\n",
    "\n",
    "\n",
    "# Create the function to generate Important Features for each sample\n",
    "def getImportantFeatures(sampNo=1):   # sampNo refers to \"Sample No.\" and;\n",
    "       \n",
    "    #Load the final lables and merge with preprocessed data\n",
    "    sample = pd.read_csv(f\"FinalLabelsSample{sampNo}.csv\")\n",
    "    \n",
    "    # Check the length of dataframe. It should be 150,000 in this case\n",
    "    print(f\"\\nSample {sampNo} size: {len(sample)}\\n\")\n",
    "    print(\"Cluster sizes:\\n\",sample['labels'].value_counts())    \n",
    "    \n",
    "    # Create an excel file to save important features for each cluster\n",
    "    writer = pd.ExcelWriter(f\"ImportantFeaturesSample{sampNo}.xlsx\", engine='xlsxwriter')\n",
    "    \n",
    "    # Tokenize the clean text and create cv_matrix\n",
    "    temp = df.merge(sample, how='inner', left_on='id', right_on='ids')\n",
    "    temp['date'] = pd.to_datetime(temp['date'])\n",
    "    temp.set_index('date', inplace=True)\n",
    "    temp['tokens'] = temp['clean_text'].apply(word_tokenize)\n",
    "    temp['tokens'] = temp['tokens'].apply(word_tokenizer)\n",
    "\n",
    "    cv = TfidfVectorizer(lowercase=False, tokenizer=lambda x:x, max_features=500)\n",
    "    cv_matrix = cv.fit_transform(temp['tokens'])\n",
    "    \n",
    "    \n",
    "    # Run the loop for each cluster and save the generated Important Features in excel file\n",
    "    for i in range(1,13):\n",
    "        print(\"\\n=========================================\")\n",
    "        temp1 = temp.copy()        \n",
    "\n",
    "        \n",
    "        # Script to create arrays to map binary cluster\n",
    "        start, stop, restart_point = i, i-1, 12\n",
    "        if stop < start:\n",
    "            stop += restart_point\n",
    "        clusterNo = []\n",
    "        for i in range(start-1, stop):\n",
    "            val = i % restart_point + 1\n",
    "            clusterNo.append(val)\n",
    "        \n",
    "        \n",
    "        # Map the binary cluster\n",
    "        temp1[f\"Binary Cluster {clusterNo[0]}\"] = temp1['labels'].map({clusterNo[0]:1, clusterNo[1]:0, clusterNo[2]:0, clusterNo[3]:0, clusterNo[4]:0, clusterNo[5]:0, clusterNo[6]:0, clusterNo[7]:0, clusterNo[8]:0, clusterNo[9]:0, clusterNo[10]:0, clusterNo[11]:0})\n",
    "        print()\n",
    "        print(f\"Training binary classifier for Cluster {clusterNo[0]}\\n\",temp1[f\"Binary Cluster {clusterNo[0]}\"].value_counts())\n",
    "\n",
    "        # Train the Supervised learning model\n",
    "        clf = RandomForestClassifier(random_state=47)\n",
    "        clf.fit(cv_matrix, temp1[f\"Binary Cluster {clusterNo[0]}\"].values)\n",
    "\n",
    "        # Sort the features w.r.t. their importance weight\n",
    "        sorted_feature_weight_idxes = np.argsort(clf.feature_importances_)[::-1]\n",
    "        most_important_features = np.take_along_axis(np.array(cv.get_feature_names()), sorted_feature_weight_idxes, axis=0)\n",
    "        most_important_weights = np.take_along_axis(np.array(clf.feature_importances_), sorted_feature_weight_idxes, axis=0)\n",
    "        print(f\"\\nSample {sampNo}, Cluster {clusterNo[0]} - Important Features with weights\\n\",list(zip(most_important_features, most_important_weights))[:10])\n",
    "        \n",
    "        # Write the featurs dataframe to local disk\n",
    "        featuredf = pd.DataFrame(list(zip(most_important_features, most_important_weights))[:50], columns=['feature','weight'])\n",
    "        featuredf.to_excel(writer, sheet_name=f'Cluster{clusterNo[0]}', index=True)\n",
    "        \n",
    "    # Save the excel file\n",
    "    writer.save()\n",
    "    \n",
    "\n",
    "# Run the function to generate important features list for Sample 1    \n",
    "getImportantFeatures()\n",
    "\n",
    "# Run the function for Sample 2\n",
    "getImportantFeatures(sampNo=2)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
